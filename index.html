<!DOCTYPE html>
<html>
<head>
  <title>P(&quot;Prediction&quot; | &quot;Text&quot;) = 1</title>
  <meta charset="utf-8">
  <meta name="description" content="P(&quot;Prediction&quot; | &quot;Text&quot;) = 1">
  <meta name="author" content="Cha Li">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="./assets/css/ribbons.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <hgroup class="auto-fadein">
    <h1>P(&quot;Prediction&quot; | &quot;Text&quot;) = 1</h1>
    <h2>Data Science Capstone Project</h2>
    <p>Cha Li<br/></p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Why Text Prediction?</h2>
  </hgroup>
  <article data-timings="">
    <p>Text prediction and modelling is a broad topic that focusses on anticipating future words, phrases, and themes
based on previous inputs. One practical application of this is auto-completion, seen in search boxes
and text messages.</p>

<p>there are many other, more novel, applications of the same basic ideas:</p>

<ul>
<li>blog post generation</li>
<li>news articles</li>
<li>generating <a href="https://pdos.csail.mit.edu/archive/scigen/">academic publications</a></li>
<li><a href="https://en.wikipedia.org/wiki/Clickbait">clickbait</a> <a href="http://community.usvsth3m.com/generator/clickbait-headline-generator">titles</a></li>
<li>speech generation for <a href="http://www.nytimes.com/2016/01/28/technology/personaltech/siri-alexa-and-other-virtual-assistants-put-to-the-test.html">virtual assistant</a> interfaces</li>
</ul>

<p>In this project, I created a simple n-gram model and wrapped it in a RShiny <a href="www.google.com">application</a></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Datasets and Preprocessing</h2>
  </hgroup>
  <article data-timings="">
    <p>The text dataset used for this project included large amounts of data taken from news stories, blog
posts, and Twitter. An exploratory analysis of the datasets can be found <a href="http://rpubs.com/chavli/ds-capstone">here</a>.</p>

<p>Text is a messy representation of a alrady chaot1c thing c4lled NachiRal lanGwicH. </p>

<h3>Preprocessing</h3>

<ol>
<li>split the data into 1000 line files for easier sampling</li>
<li>normalized everything to lower-case </li>
<li>removed symbols and punctuation, except apostrophes </li>
<li>removed redundant whitespace</li>
<li>handle misspellings / typos</li>
</ol>

<p>I decided to keep stopwords (words with little contextual meaning) since they have a bigger role in 
text prediction than in topic modelling. Stopwords are valid predictions!</p>

<p><a href="https://swiftkey.com/en">SwiftKey</a> and <a href="www.coursera.com">Coursera</a> provided the datasets.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Algorithms and Models</h2>
  </hgroup>
  <article data-timings="">
    <p>The five components of my approach to this project were</p>

<ol>
<li>basic NLP to parse out words and sentences</li>
<li>uni-gram, bi-gram, and tri-gram frequencies and relationships</li>
<li><a href="https://en.wikipedia.org/wiki/Katz%27s_back-off_model">katz-backoff model</a> with <a href="http://nlp.stanford.edu/%7Ewcmac/papers/20050421-smoothing-tutorial.pdf">smoothing</a> + <a href="https://pdfs.semanticscholar.org/2905/3eab305c2b585bcfbb713243b05646e7d62d.pdf">pruning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Graphical_model">graphical models</a> and <a href="https://en.wikipedia.org/wiki/Markov_chain">markov chains</a> </li>
<li>model optimization and evaluation</li>
</ol>

<p>Two problems arise from this approach: sparsity and efficient storage of the model</p>

<h3>R packages</h3>

<p>The primary R libraries I used for language modelling were <code>tm</code>, <code>igraph</code>, <code>markovchain</code>, <code>ngram</code>, and <code>NLP</code>. 
<code>dplyr</code> and <code>tidyr</code> were used to format datasets and <code>caret</code> was used for cross-validation.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Optimization</h2>
  </hgroup>
  <article data-timings="">
    <p><em>This is where the math hits the silicon.</em></p>

<h3>Speed</h3>

<p>The compute intensive portions of my code took advantage of multiple cores using the <code>parallel::mclapply</code> 
and <code>parallel:mcmapply</code> functions. Training is a perfect application for parallelization since a large 
corpora can be easily distributed. Prediction is also parallelized with each n-gram order being 
handled by a different core. Improvement in speed is roughly linear with the core count.</p>

<h3>Memory</h3>

<p>Relationships between phrases and words can be <strong>numerous and sparse</strong>, a bad combination that leads
to a lot of wasted memory. <a href="https://pdfs.semanticscholar.org/2905/3eab305c2b585bcfbb713243b05646e7d62d.pdf">Pruning</a>
is one method for removing trivial n-grams. Another solution is to use an <a href="https://en.wikipedia.org/wiki/Sparse_matrix#Storing_a_sparse_matrix">efficient method</a> for representing sparse data. 
<code>igraph::as_adjacency_matrix</code> provides an easy method to accomplish the latter. A smaller memory 
footprint also improves model speed.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Results</h2>
  </hgroup>
  <article data-timings="">
    <p>The vast majority of my modelling work: analysis, training, and testing was done using RStudio Server
hosted on <a href="https://aws.amazon.com/ec2/instance-types/#compute-optimized">EC2</a>.</p>

<p>insert some graphs here</p>

<h3>The Shiny App</h3>

<p>You can play around with my final text-prediction model using my RShiny app found <a href="www.google.com">here</a>. 
It&#39;s hosted on an EC2 instance rather than shinyapps.io because I&#39;m not paying $40 / month for 2GB of RAM.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='Why Text Prediction?'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Datasets and Preprocessing'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Algorithms and Models'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Optimization'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Results'>
         5
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>